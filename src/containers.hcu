/*---------------------------------------------------------------------------*\
 *
 *  minimmerflow
 *
 *  Copyright (C) 2015-2021 OPTIMAD engineering Srl
 *
 *  -------------------------------------------------------------------------
 *  License
 *  This file is part of minimmerflow.
 *
 *  minimmerflow is free software: you can redistribute it and/or modify it
 *  under the terms of the GNU Lesser General Public License v3 (LGPL)
 *  as published by the Free Software Foundation.
 *
 *  minimmerflow is distributed in the hope that it will be useful, but WITHOUT
 *  ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 *  FITNESS FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public
 *  License for more details.
 *
 *  You should have received a copy of the GNU Lesser General Public License
 *  along with minimmerflow. If not, see <http://www.gnu.org/licenses/>.
 *
\*---------------------------------------------------------------------------*/

#ifndef __MINIMMERFLOW_CONTAINERS_HCU__
#define __MINIMMERFLOW_CONTAINERS_HCU__

#include "containers.hpp"

namespace containers {

template<typename dev_value_t>
__global__ void dev_setValue(std::size_t nElements, dev_value_t value, dev_value_t *data);

}

template<typename value_t>
class DeviceCollectionDataCursor
{
public:
    __device__ DeviceCollectionDataCursor();
    __device__ DeviceCollectionDataCursor(value_t **data, std::size_t offset);

    __device__ void set(std::size_t offset);
    __device__ void set(value_t **data, std::size_t offset);

    __device__ value_t & operator[](int index);
    __device__ const value_t & operator[](int index) const;

    __device__ value_t * data(int index);
    __device__ const value_t * data(int index) const;

private:
    value_t **m_collectionData;
    std::size_t m_offset;

};

template<typename value_t>
class DeviceCollectionDataConstCursor
{
public:
    __device__ DeviceCollectionDataConstCursor();
    __device__ DeviceCollectionDataConstCursor(const value_t * const *data, std::size_t offset);

    __device__ void set(std::size_t offset);
    __device__ void set(const value_t * const *data, std::size_t offset);

    __device__ const value_t & operator[](int index) const;

    __device__ const value_t * data(int index) const;

private:
    const value_t * const *m_collectionData;
    std::size_t m_offset;

};

template<typename value_t>
class DeviceStridedDataCursor
{
public:
    __device__ DeviceStridedDataCursor();
    __device__ DeviceStridedDataCursor(value_t *data, std::size_t offset, int stride = 1);

    __device__ void set(value_t *data, std::size_t offset, int stride = 1);

    __device__ value_t & operator[](int index);
    __device__ const value_t & operator[](int index) const;

    __device__ value_t * data(int index);
    __device__ const value_t * data(int index) const;

private:
    value_t *m_data;

};

template<typename value_t>
class DeviceStridedDataConstCursor
{
public:
    __device__ DeviceStridedDataConstCursor();
    __device__ DeviceStridedDataConstCursor(const value_t *data, std::size_t offset, int stride = 1);

    __device__ void set(const value_t *data, std::size_t offset, int stride = 1);

    __device__ const value_t & operator[](int index) const;

    __device__ const value_t * data(int index) const;

private:
    const value_t *m_data;

};

/**
 * \ingroup containers
 *
 * Allow to access data of arrays stored on the device.
 */

template<typename value_t>
class DeviceProxyArray
{

public:
    __device__ DeviceProxyArray(int stride = 1);
    __device__ DeviceProxyArray(value_t *data, std::size_t offset, int stride = 1);

    __device__ void set(value_t *data, std::size_t offset);

    __device__ value_t & operator[](int index);
    __device__ const value_t & operator[](int index) const;

protected:
    value_t *m_data;
    const int m_stride;

};

/**
 * \ingroup containers
 * \class DeviceSharedArray
 *
 * Allow to access data stored fa arrays stored in shared memory.
 *
 * Shared memory has 32 banks that are organized such that successive 32-bit
 * words map to successive banks. One efficient way to store an array in shared
 * memory is to logically assign the elements of an array to the threads of the
 * thread block so that all elements of our new virtual private array for each
 * thread are stored in its own shared memory bank. Here the first BLOCK_SIZE
 * elements of the shared memory array contain all 0-index elements of the
 * private arrays for all threads of the thread block. The next BLOCK_SIZE
 * elements of the shared memory array contain all 1-index elements of the
 * private arrays, and so on. In this way we ensure that the whole virtual
 * private array of thread 0 falls into shared memory bank 0, the array of
 * thread 1 falls into bank 1, and so on. Thread 32—which is the first thread
 * in the next warp—will occupy bank 0 again but there will be no shared memory
 * bank conflicts with thread 0 (or any other bank 0 thread) since they belong
 * to different warps and therefore will never read at the same instant.
 * This can be achived setting the stride to the block size and the offset to
 * the id of the current thread.
 *
 * See:
 *
 *  https://developer.nvidia.com/blog/fast-dynamic-indexing-private-arrays-cuda
 */

template<typename value_t>
class DeviceSharedArray : public DeviceProxyArray<value_t>
{

public:
    __device__ static int evaluateSharedSize(int size);

    __device__ DeviceSharedArray();
    __device__ DeviceSharedArray(value_t *data);

    __device__ void set(value_t *data);

};

#endif
